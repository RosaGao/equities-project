{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TPPHRM data and data processing//selected_factor_and_return.csv', index_col='date').drop(columns=['Unnamed: 0'])\n",
    "df=df.dropna(subset=['Size', 'Liquidity', 'cpv_1mo', 'mr_1yr', 'mr_1w'], how='all')\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "ret_1d = df[['Ticker','daily_return']]\n",
    "data_1d = df.drop(columns=['daily_return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Size</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>cpv_1mo</th>\n",
       "      <th>mr_1yr</th>\n",
       "      <th>mr_1w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-03-02</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.381918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-03</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>0.426358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.462423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-04</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>-1.005234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.477961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-07</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>-0.731422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.398283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-08</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>-1.081762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.433256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-22</th>\n",
       "      <td>4887.T</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.312916</td>\n",
       "      <td>-0.967226</td>\n",
       "      <td>-1.227663</td>\n",
       "      <td>1.173214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>4887.T</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.312916</td>\n",
       "      <td>-1.061441</td>\n",
       "      <td>-1.209116</td>\n",
       "      <td>-0.017219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>4887.T</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.312916</td>\n",
       "      <td>-1.163607</td>\n",
       "      <td>-1.202994</td>\n",
       "      <td>-0.882076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>4887.T</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.312916</td>\n",
       "      <td>-1.065248</td>\n",
       "      <td>-1.200425</td>\n",
       "      <td>1.144204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>4887.T</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.312916</td>\n",
       "      <td>-1.059960</td>\n",
       "      <td>-1.204539</td>\n",
       "      <td>1.191659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150704 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ticker      Size  Liquidity   cpv_1mo    mr_1yr     mr_1w\n",
       "date                                                                 \n",
       "2005-03-02  4151.T  0.603338  -0.370407  0.000000  0.000000 -1.381918\n",
       "2005-03-03  4151.T  0.603338  -0.370407  0.426358  0.000000 -0.462423\n",
       "2005-03-04  4151.T  0.603338  -0.370407 -1.005234  0.000000 -1.477961\n",
       "2005-03-07  4151.T  0.603338  -0.370407 -0.731422  0.000000 -0.398283\n",
       "2005-03-08  4151.T  0.603338  -0.370407 -1.081762  0.000000 -1.433256\n",
       "...            ...       ...        ...       ...       ...       ...\n",
       "2024-02-22  4887.T  0.052614   0.312916 -0.967226 -1.227663  1.173214\n",
       "2024-02-26  4887.T  0.052614   0.312916 -1.061441 -1.209116 -0.017219\n",
       "2024-02-27  4887.T  0.052614   0.312916 -1.163607 -1.202994 -0.882076\n",
       "2024-02-28  4887.T  0.052614   0.312916 -1.065248 -1.200425  1.144204\n",
       "2024-02-29  4887.T  0.052614   0.312916 -1.059960 -1.204539  1.191659\n",
       "\n",
       "[150704 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-09-20 2013-09-03 2014-08-20\n"
     ]
    }
   ],
   "source": [
    "train_end_1 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.4)]\n",
    "val_end_1 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.45)]\n",
    "test_end_1 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.5)]\n",
    "print(train_end_1,val_end_1,test_end_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-11-05 2017-07-06 2018-05-31 2019-05-13\n"
     ]
    }
   ],
   "source": [
    "train_start_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.25)]\n",
    "train_end_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.65)]\n",
    "val_end_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.7)]\n",
    "test_end_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.75)]\n",
    "print(train_start_2,train_end_2,val_end_2,test_end_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-08-20 2022-03-31 2023-03-16\n"
     ]
    }
   ],
   "source": [
    "train_start_3 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.5)]\n",
    "train_end_3 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.9)]\n",
    "val_end_3 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.95)]\n",
    "print(train_start_3,train_end_3,val_end_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = data_1d[data_1d.index <= train_end_1]\n",
    "val_data_1 = data_1d[(data_1d.index > train_end_1) & (data_1d.index <= val_end_1)]\n",
    "test_data_1 = data_1d[(data_1d.index > val_end_1) & (data_1d.index <= test_end_1)]\n",
    "\n",
    "train_data_2 = data_1d[(data_1d.index > train_start_2) & (data_1d.index <= train_end_2) ]\n",
    "val_data_2 = data_1d[(data_1d.index > train_end_2) & (data_1d.index <= val_end_2)]\n",
    "test_data_2 = data_1d[(data_1d.index > val_end_2) & (data_1d.index <= test_end_2)]\n",
    "\n",
    "train_data_3 = data_1d[(data_1d.index > train_start_3) & (data_1d.index <= train_end_3) ]\n",
    "val_data_3 = data_1d[(data_1d.index > train_end_3) & (data_1d.index <= val_end_3)]\n",
    "test_data_3 = data_1d[(data_1d.index > val_end_3) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def make_samples(data_1d, ret, seq_len):\n",
    "    COLUMNS = data_1d.columns.drop('Ticker')\n",
    "    sample_idxs = []\n",
    "    df = data_1d.copy()\n",
    "    for code, dt in tqdm(df.groupby('Ticker'), desc='rolling idx'):\n",
    "         dt['date_'] = dt.index\n",
    "         for ts in list(dt['date_'].rolling(seq_len))[seq_len-1:]:\n",
    "             sample_idxs.append((code, ts.values.tolist()))\n",
    "    x_1d, y, idx, codes =  [], [], [], []\n",
    "    for code, times in tqdm(sample_idxs, desc='make_sample'):\n",
    "        x_code_1d = data_1d[data_1d['Ticker']==code]\n",
    "        ret_code = ret[ret['Ticker'] == code]\n",
    "        x_1d.append(x_code_1d.loc[times, COLUMNS].values)\n",
    "        y.append(ret_code.loc[times[-1], 'daily_return'])\n",
    "        idx.append(times[-1])\n",
    "        codes.append(code)\n",
    "    return x_1d, y, idx, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rolling idx: 100%|██████████████████████████████| 32/32 [00:00<00:00, 58.57it/s]\n",
      "make_sample: 100%|███████████████████████| 52311/52311 [05:32<00:00, 157.21it/s]\n",
      "rolling idx: 100%|█████████████████████████████| 33/33 [00:00<00:00, 295.87it/s]\n",
      "make_sample: 100%|█████████████████████████| 7522/7522 [00:34<00:00, 218.18it/s]\n",
      "rolling idx: 100%|█████████████████████████████| 34/34 [00:00<00:00, 374.84it/s]\n",
      "make_sample: 100%|█████████████████████████| 7775/7775 [00:36<00:00, 212.94it/s]\n",
      "rolling idx: 100%|██████████████████████████████| 35/35 [00:00<00:00, 50.76it/s]\n",
      "make_sample: 100%|███████████████████████| 60193/60193 [06:16<00:00, 159.94it/s]\n",
      "rolling idx: 100%|█████████████████████████████| 35/35 [00:00<00:00, 230.46it/s]\n",
      "make_sample: 100%|█████████████████████████| 8085/8085 [00:37<00:00, 216.65it/s]\n",
      "rolling idx: 100%|█████████████████████████████| 35/35 [00:00<00:00, 337.11it/s]\n",
      "make_sample: 100%|█████████████████████████| 8085/8085 [00:45<00:00, 178.95it/s]\n",
      "rolling idx: 100%|██████████████████████████████| 37/37 [00:00<00:00, 39.22it/s]\n",
      "make_sample: 100%|███████████████████████| 65123/65123 [07:12<00:00, 150.71it/s]\n",
      "rolling idx: 100%|█████████████████████████████| 37/37 [00:00<00:00, 534.82it/s]\n",
      "make_sample: 100%|█████████████████████████| 8547/8547 [00:39<00:00, 217.29it/s]\n",
      "rolling idx: 100%|█████████████████████████████| 39/39 [00:00<00:00, 304.16it/s]\n",
      "make_sample: 100%|█████████████████████████| 8578/8578 [00:41<00:00, 205.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    # Generate training set samples\n",
    "    x_train, y_train, idx_train, code_train = make_samples(globals()[f'train_data_{i}'], ret_1d, 5)\n",
    "    np.save(f'data_rolling_3/x_train_{i}.npy', x_train)\n",
    "    np.save(f'data_rolling_3/y_train_{i}.npy', y_train)\n",
    "    np.save(f'data_rolling_3/idx_train_{i}.npy', idx_train)\n",
    "    np.save(f'data_rolling_3/code_train_{i}.npy', code_train)\n",
    "\n",
    "    # Generate validation set samples\n",
    "    x_val, y_val, idx_val, code_val = make_samples(globals()[f'val_data_{i}'], ret_1d, 5)\n",
    "    np.save(f'data_rolling_3/x_val_{i}.npy', x_val)\n",
    "    np.save(f'data_rolling_3/y_val_{i}.npy', y_val)\n",
    "    np.save(f'data_rolling_3/idx_val_{i}.npy', idx_val)\n",
    "    np.save(f'data_rolling_3/code_val_{i}.npy', code_val)\n",
    "\n",
    "    # Generate test set samples\n",
    "    x_test, y_test, idx_test, code_test = make_samples(globals()[f'test_data_{i}'], ret_1d, 5)\n",
    "    np.save(f'data_rolling_3/x_test_{i}.npy', x_test)\n",
    "    np.save(f'data_rolling_3/y_test_{i}.npy', y_test)\n",
    "    np.save(f'data_rolling_3/idx_test_{i}.npy', idx_test)\n",
    "    np.save(f'data_rolling_3/code_test_{i}.npy', code_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
