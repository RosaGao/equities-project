{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Size</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>cpv_1mo</th>\n",
       "      <th>mr_1yr</th>\n",
       "      <th>mr_1w</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-03-02</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.381918</td>\n",
       "      <td>-0.007344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-03</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>0.426358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.462423</td>\n",
       "      <td>0.016029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-04</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>-1.005234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.477961</td>\n",
       "      <td>-0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-07</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>-0.731422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.398283</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-08</th>\n",
       "      <td>4151.T</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.370407</td>\n",
       "      <td>-1.081762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.433256</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ticker      Size  Liquidity   cpv_1mo  mr_1yr     mr_1w  \\\n",
       "date                                                                  \n",
       "2005-03-02  4151.T  0.603338  -0.370407       NaN     NaN -1.381918   \n",
       "2005-03-03  4151.T  0.603338  -0.370407  0.426358     NaN -0.462423   \n",
       "2005-03-04  4151.T  0.603338  -0.370407 -1.005234     NaN -1.477961   \n",
       "2005-03-07  4151.T  0.603338  -0.370407 -0.731422     NaN -0.398283   \n",
       "2005-03-08  4151.T  0.603338  -0.370407 -1.081762     NaN -1.433256   \n",
       "\n",
       "            daily_return  \n",
       "date                      \n",
       "2005-03-02     -0.007344  \n",
       "2005-03-03      0.016029  \n",
       "2005-03-04     -0.001213  \n",
       "2005-03-07      0.001215  \n",
       "2005-03-08      0.002427  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('selected_factor_and_return.csv')\n",
    "df.set_index(['date'], inplace=True)\n",
    "\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "  df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of features and target column\n",
    "features_cols = df.columns[1:-1]\n",
    "target_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains NaN: False\n",
      "Contains infinite values: False\n"
     ]
    }
   ],
   "source": [
    "target = df[target_col]\n",
    "has_nan = target.isnull().values.any()\n",
    "print(\"Contains NaN:\", has_nan)\n",
    "\n",
    "has_inf = target.isin([np.inf, -np.inf]).values.any()\n",
    "print(\"Contains infinite values:\", has_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['Size', 'Liquidity', 'cpv_1mo', 'mr_1yr', 'mr_1w'], how='all')\n",
    "df.fillna(0, inplace=True)\n",
    "data_1d = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end_1 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.4)]\n",
    "val_end_1 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.45)]\n",
    "test_end_1 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.5)]\n",
    "\n",
    "train_start_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.25)]\n",
    "train_end_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.65)]\n",
    "val_end_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.7)]\n",
    "test_end_2 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.75)]\n",
    "\n",
    "train_start_3 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.5)]\n",
    "train_end_3 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.9)]\n",
    "val_end_3 = data_1d.index.unique()[int(len(data_1d.index.unique())*0.95)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = data_1d[data_1d.index <= train_end_1]\n",
    "val_data_1 = data_1d[(data_1d.index > train_end_1) & (data_1d.index <= val_end_1)]\n",
    "test_data_1 = data_1d[(data_1d.index > val_end_1) & (data_1d.index <= test_end_1)]\n",
    "\n",
    "train_data_2 = data_1d[(data_1d.index > train_start_2) & (data_1d.index <= train_end_2) ]\n",
    "val_data_2 = data_1d[(data_1d.index > train_end_2) & (data_1d.index <= val_end_2)]\n",
    "test_data_2 = data_1d[(data_1d.index > val_end_2) & (data_1d.index <= test_end_2)]\n",
    "\n",
    "train_data_3 = data_1d[(data_1d.index > train_start_3) & (data_1d.index <= train_end_3) ]\n",
    "val_data_3 = data_1d[(data_1d.index > train_end_3) & (data_1d.index <= val_end_3)]\n",
    "test_data_3 = data_1d[(data_1d.index > val_end_3)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52439 entries, 2005-03-02 to 2012-09-20\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Size       52439 non-null  float64\n",
      " 1   Liquidity  52439 non-null  float64\n",
      " 2   cpv_1mo    52439 non-null  float64\n",
      " 3   mr_1yr     52439 non-null  float64\n",
      " 4   mr_1w      52439 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loop through the groups 1 to 3\n",
    "for i in range(1, 4):\n",
    "    # Process training data\n",
    "    globals()[f'y_train_{i}'] = globals()[f'train_data_{i}'][target_col].copy()\n",
    "    globals()[f'X_train_{i}'] = globals()[f'train_data_{i}'][features_cols].copy()\n",
    "\n",
    "    # Process validation data\n",
    "    globals()[f'y_val_{i}'] = globals()[f'val_data_{i}'][target_col].copy()\n",
    "    globals()[f'X_val_{i}'] = globals()[f'val_data_{i}'][features_cols].copy()\n",
    "\n",
    "    # Process testing data\n",
    "    globals()[f'y_test_{i}'] = globals()[f'test_data_{i}'][target_col].copy()\n",
    "    globals()[f'X_test_{i}'] = globals()[f'test_data_{i}'][features_cols].copy()\n",
    "\n",
    "\n",
    "X_train_1.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stock returns in the following two days are split to two target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [200,400],\n",
    "    'learning_rate': [0.001, 0.005],\n",
    "    'max_depth': [8, 10],\n",
    "    'gamma': [0.001,  0.01],\n",
    "    'random_state': [42]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Round 1\n",
      "Best params: {'gamma': 0.001, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 200, 'random_state': 42}\n",
      "Best validation score = 0.0010135258932433943\n",
      "Predicted cross-section IC: -0.0242\n",
      "mean_squared_error = 0.0003154396565919581\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Round 2\n",
      "Best params: {'gamma': 0.001, 'learning_rate': 0.005, 'max_depth': 8, 'n_estimators': 400, 'random_state': 42}\n",
      "Best validation score = 0.002939120274534002\n",
      "Predicted cross-section IC: -0.0034\n",
      "mean_squared_error = 0.0004685664087873538\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Round 3\n",
      "Best params: {'gamma': 0.001, 'learning_rate': 0.005, 'max_depth': 10, 'n_estimators': 400, 'random_state': 42}\n",
      "Best validation score = 0.0049158610237910235\n",
      "Predicted cross-section IC: 0.0076\n",
      "mean_squared_error = 0.00032395473866185027\n",
      "Completed processing all groups.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1, 4):\n",
    "    # Constructing the eval_set with validation data\n",
    "    eval_set = [(globals()[f'X_train_{i}'], globals()[f'y_train_{i}']), (globals()[f'X_val_{i}'], globals()[f'y_val_{i}'])]\n",
    "\n",
    "    # Initialize the model\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', verbose=False)\n",
    "    clf = GridSearchCV(model, parameters, verbose=1)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(globals()[f'X_train_{i}'], globals()[f'y_train_{i}'])\n",
    "\n",
    "    print(f'Round {i}')\n",
    "    print(f'Best params: {clf.best_params_}')\n",
    "    print(f'Best validation score = {clf.best_score_}')\n",
    "\n",
    "    # Fitting the model with the best parameters\n",
    "    model = xgb.XGBRegressor(**clf.best_params_, objective='reg:squarederror')\n",
    "    model.fit(globals()[f'X_train_{i}'], globals()[f'y_train_{i}'], eval_set=eval_set, verbose=False)\n",
    "\n",
    "    # Plot feature importance\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    xgb.plot_importance(model, ax=ax)\n",
    "    plt.savefig(f'XGB figure importance/feature_importance_{i}.png') \n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(globals()[f'X_test_{i}'])\n",
    "    \n",
    "    test_date = globals()[f'y_test_{i}'].index\n",
    "    test_ticker = globals()[f'test_data_{i}'].Ticker\n",
    "    pred_date_df = pd.DataFrame(test_date.to_list()).rename(columns={0: 'date'})\n",
    "    pred_ticker_df = pd.DataFrame(test_ticker).reset_index(drop=True)\n",
    "    y_pred_df = pd.DataFrame(y_pred).rename(columns={0: 'prediction'})\n",
    "    pred_df = pd.concat([pred_date_df, pred_ticker_df, y_pred_df], axis=1)\n",
    "\n",
    "    # calculate ic\n",
    "    pred_pivot = pred_df.pivot(index='date', columns='Ticker', values='prediction').fillna(0)\n",
    "    obs_pivot = globals()[f'test_data_{i}'][['Ticker','daily_return']].reset_index().pivot(index='date', columns='Ticker', values='daily_return').fillna(0)  \n",
    "\n",
    "    ic = pred_pivot.corrwith(obs_pivot, axis=1).mean()\n",
    "    print(f\"Predicted cross-section IC: {ic:.4f}\")\n",
    "    \n",
    "    mse = mean_squared_error(globals()[f'y_test_{i}'], y_pred)\n",
    "    print(f'mean_squared_error = {mse}')\n",
    "    \n",
    "    \n",
    "    # save final round predict\n",
    "    pred_df.to_csv(f'backtest/predict data/XGB_rolling_test_3_round_{i}.csv', index=False)\n",
    "\n",
    "    valid_date = globals()[f'y_val_{i}'].index\n",
    "    valid_ticker = globals()[f'val_data_{i}'].Ticker\n",
    "    valid_y_pred = model.predict(globals()[f'X_val_{i}'])\n",
    "    valid_pred_date_df = pd.DataFrame(valid_date.to_list()).rename(columns={0: 'date'})\n",
    "    valid_pred_ticker_df = pd.DataFrame(valid_ticker).reset_index(drop=True)\n",
    "    valid_y_pred_df = pd.DataFrame(valid_y_pred).rename(columns={0: 'prediction'})\n",
    "    valid_pred_df = pd.concat([valid_pred_date_df, valid_pred_ticker_df, valid_y_pred_df], axis=1)\n",
    "\n",
    "    valid_pred_df.to_csv(f'backtest/predict data/XGB_rolling_val_3_round_{i}.csv', index=False)\n",
    "\n",
    "print(\"Completed processing all groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 34407,
     "sourceId": 4504,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30005,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
